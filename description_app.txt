======= Automated Linguistic Annotation =======

1. Description

This is a Natural Language Processing (NLP) App built with Streamlit and 
state-of-the-art Python packages for NLP such as spaCy and NLTK.

The app's interface is very simple. It consists of a sidebar and a main section. 
*** The sidebar contains a multiselect field called Annotators which allows users to
select the annotators they want to run on their input text.
*** The main section contains a text area in which the user can enter the text they want to analyze.

The current version of the app:

    - tokenizes the input sentence/text
    - assigns parts of speech to the tokens
    - extracts the lemmas
    - extracts the Noun Phrases (NPs)
    - extracts the lexical words from the input sentence/text
    - parses and visualizes the dependency relations
    - parses the constituents
    - analyzes the sentiment of the text
    - extracts the keywords of the input text
    - represents the semantic structure of sentences in formulas of first-order logic

This automated tool can find a good implementation in English teaching scenarios and more specifically, it can be a useful complement to
teaching/learning English Grammar.
The app can be dynamically updated with more features such as a constituency parser, morphological analyzer, etc. depending on the 
needs of the tutors.

2. Packages:
It currently uses the following python packages:
- streamlit - a python library for producing web apps,
- spacy - a python library for NLP (the library is used for the tokenization, the POS-tagging, the lemmatization, the NP chunking,
the extraction of content words, and parsing of the dependency relations), 
- displacy - a spacy visualizer of the dependency relations between words,
- NLTK VADER - an NLTK built-in pretrained model for sentiment analysis, 
- NLTK - a python library for NLP (used for the representation of the semantic structure of sentences using formula of first-order logic),
- benepar - the Berkeley Neural Parser with SpaCy for constituency analysis,
- keybert - a python package for the extraction of keywords which are most similar to the document.


3. How it works (for front-end users)

2.1. First, enter your text in the text area.
2.2. Then, choose the annotator(s) you want to run on your text.
2.3. Finally, press the "Analyze" button.
2.4. The annotations will appear in the main section below the text area.
2.5. The annotations are stored in tables which can be downloaded as csv files for further analysis.
